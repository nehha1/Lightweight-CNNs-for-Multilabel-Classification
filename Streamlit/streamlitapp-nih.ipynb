{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":249206422,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q streamlit pyngrok","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:46:33.279769Z","iopub.execute_input":"2025-07-08T15:46:33.280537Z","iopub.status.idle":"2025-07-08T15:46:39.898474Z","shell.execute_reply.started":"2025-07-08T15:46:33.280509Z","shell.execute_reply":"2025-07-08T15:46:39.897573Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%writefile main_app.py\n# --- Core Libraries ---\nimport streamlit as st\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport cv2 # OpenCV for image manipulation\nimport tensorflow as tf\nimport os\n\n# --- App Configuration ---\nst.set_page_config(\n    page_title=\"Chest X-Ray Analysis\",\n    page_icon=\"ğŸ«\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n\n# --- Custom CSS for UI Enhancement ---\nst.markdown(\"\"\"\n<style>\n    /* Main app background */\n    .stApp {\n        background-color: #0E1117;\n    }\n    /* Card-like containers for sections */\n    .st-emotion-cache-1r4qj8v {\n        background-color: #161B22;\n        border: 1px solid #30363D;\n        border-radius: 10px;\n        padding: 25px;\n        box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);\n    }\n    /* Main title styling */\n    h1 {\n        color: #FFFFFF;\n        text-align: center;\n    }\n    /* Subheader styling */\n    h2 {\n        color: #58A6FF;\n        border-bottom: 2px solid #30363D;\n        padding-bottom: 10px;\n    }\n    /* Styling for the metric label */\n    .st-emotion-cache-1g8m52x {\n        color: #8B949E;\n    }\n    /* Analyze button styling */\n    .stButton > button {\n        background-color: #238636;\n        color: white;\n        border-radius: 8px;\n        border: none;\n        padding: 10px 20px;\n        width: 100%;\n        font-size: 16px;\n    }\n    .stButton > button:hover {\n        background-color: #2EA043;\n    }\n    .stButton > button:disabled {\n        background-color: #30363D;\n        color: #8B949E;\n    }\n    /* File uploader styling */\n    .st-emotion-cache-1fttcpj {\n        background-color: #0D1117;\n        border: 1px dashed #30363D;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n\n# --- Model & Label Definitions ---\n# This MUST match the number of outputs from your model's final layer.\nFINAL_14_LABELS = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n    'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule',\n    'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'\n]\nIMG_SIZE = 224\n\n# --- Custom Loss Function Definition ---\ndef get_weighted_loss(weights):\n    weights = tf.constant(weights, dtype=tf.float32)\n    def weighted_loss(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n        loss_weights = (weights[:, 1] * y_true) + (weights[:, 0] * (1 - y_true))\n        weighted_bce = loss_weights * bce\n        return tf.keras.backend.mean(weighted_bce)\n    return weighted_loss\n\n# --- Model Loading (with caching) ---\n@st.cache_resource\ndef load_keras_model(model_path):\n    if not os.path.exists(model_path):\n        st.error(f\"Model file not found at {model_path}. Please check the path.\")\n        st.info(\"Make sure you have added your Kaggle Dataset containing the model to this notebook.\")\n        return None\n    try:\n        # We need a dummy weights array to pass to the loss function loader\n        dummy_weights = np.ones((len(FINAL_14_LABELS), 2))\n        custom_objects = {'weighted_loss': get_weighted_loss(dummy_weights)}\n        model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n        st.success(\"Model loaded successfully!\")\n        return model\n    except Exception as e:\n        st.error(f\"Error loading model: {e}\")\n        return None\n\n# --- Real Prediction & Preprocessing Functions ---\ndef preprocess_image(image: Image.Image):\n    img = image.convert('L') # Convert to grayscale\n    img_array = np.array(img)\n    \n    # Use TensorFlow for preprocessing\n    img_tf = tf.convert_to_tensor(img_array, dtype=tf.uint8)\n    img_tf = tf.expand_dims(img_tf, axis=-1)\n    img_tf = tf.io.decode_png(tf.io.encode_png(img_tf), channels=1)\n    img_tf = tf.image.convert_image_dtype(img_tf, tf.float32)\n    img_tf = tf.image.grayscale_to_rgb(img_tf)\n    img_tf = tf.image.resize(img_tf, [IMG_SIZE, IMG_SIZE])\n    return tf.expand_dims(img_tf, axis=0)\n\ndef predict_with_model(model, processed_img_batch):\n    st.info(\"Running inference...\")\n    prediction_array = model.predict(processed_img_batch)[0]\n    predictions = dict(zip(FINAL_14_LABELS, prediction_array))\n    return predictions\n\n# --- Streamlit App Interface ---\nst.title(\"ğŸ« Chest X-Ray Diagnostic Assistant\")\nst.markdown(\"<p style='text-align: center; color: #8B949E;'>Upload a chest X-ray and patient information for an AI-powered analysis.</p>\", unsafe_allow_html=True)\nst.markdown(\"---\")\n\nMODEL_PATH = '/kaggle/input/mobilenet-v2-nih-full-dataset-further-fine-tuning/best_chest_xray_model.keras'\nmodel = load_keras_model(MODEL_PATH)\n\n# --- Input Section ---\nwith st.container(border=True):\n    st.header(\"ğŸ‘¤ Patient Information & Upload\")\n    patient_name = st.text_input(\"Patient Name\", \"John Doe\")\n    patient_age = st.number_input(\"Patient Age\", min_value=0, max_value=120, value=55, step=1)\n    patient_gender = st.selectbox(\"Gender\", [\"Male\", \"Female\", \"Other\"])\n    \n    uploaded_file = st.file_uploader(\"Upload X-Ray Image\", type=['png', 'jpg', 'jpeg'])\n    \n    st.markdown(\"<br>\", unsafe_allow_html=True) # Spacer\n    analyze_button = st.button(\"Analyze X-Ray\", use_container_width=True, disabled=(model is None or uploaded_file is None))\n\nst.markdown(\"---\")\n\n# --- Results Section ---\nif analyze_button:\n    with st.container(border=True):\n        st.header(\"ğŸ“Š Analysis Results\")\n        image = Image.open(uploaded_file)\n        st.image(image, caption=f\"Uploaded X-Ray for {patient_name}\", use_container_width=True)\n        \n        with st.spinner(\"Running analysis... Please wait.\"):\n            # Preprocess image and get predictions\n            processed_img_batch = preprocess_image(image)\n            predictions = predict_with_model(model, processed_img_batch)\n            \n        st.success(\"Analysis Complete!\")\n        st.subheader(\"ğŸ©º Model Predictions\")\n        pred_df = pd.DataFrame(predictions.items(), columns=['Condition', 'Probability']).sort_values(by='Probability', ascending=False).reset_index(drop=True)\n        top_prediction_df = pred_df.iloc[0]\n        st.metric(label=\"Most Likely Condition\", value=top_prediction_df['Condition'], delta=f\"{top_prediction_df['Probability']:.2%}\")\n        \n        with st.expander(\"View Full Probability Distribution\"):\n            st.bar_chart(pred_df.set_index('Condition'))\nelse:\n    st.info(\"Please provide patient info, upload an X-ray, and click 'Analyze' to view the results.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:54:44.561578Z","iopub.execute_input":"2025-07-08T15:54:44.561894Z","iopub.status.idle":"2025-07-08T15:54:44.571133Z","shell.execute_reply.started":"2025-07-08T15:54:44.561864Z","shell.execute_reply":"2025-07-08T15:54:44.570154Z"}},"outputs":[{"name":"stdout","text":"Overwriting main_app.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom pyngrok import ngrok\n\n# Get the authtoken from Kaggle Secrets\ntry:\n    user_secrets = UserSecretsClient()\n    NGROK_AUTH_TOKEN = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\nexcept:\n    print(\"Ngrok authtoken not found. Please add it to this notebook's secrets.\")\n    NGROK_AUTH_TOKEN = \"\"\n\nif NGROK_AUTH_TOKEN:\n    # Terminate any existing ngrok tunnels\n    ngrok.kill()\n\n    # Set the authtoken for ngrok\n    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n    # Set up the public URL.\n    public_url = ngrok.connect(8501)\n    print(f\"Click to open your Streamlit app: {public_url}\")\n\n    # Run the Streamlit app\n    !streamlit run main_app.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:54:48.363990Z","iopub.execute_input":"2025-07-08T15:54:48.364308Z","iopub.status.idle":"2025-07-08T16:05:28.253093Z","shell.execute_reply.started":"2025-07-08T15:54:48.364283Z","shell.execute_reply":"2025-07-08T16:05:28.252261Z"}},"outputs":[{"name":"stdout","text":"Click to open your Streamlit app: NgrokTunnel: \"https://d8daf4e01d89.ngrok-free.app\" -> \"http://localhost:8501\"\n\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\u001b[0m\n\u001b[0m\n\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n\u001b[0m\n\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.234.110:8501\u001b[0m\n\u001b[0m\n2025-07-08 15:55:00.519141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751990100.548871     242 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751990100.557746     242 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-07-08 15:55:05.415860: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n^C\n\u001b[34m  Stopping...\u001b[0m\n","output_type":"stream"}],"execution_count":10}]}